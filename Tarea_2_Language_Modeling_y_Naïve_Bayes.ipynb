{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cristobalperezp/CC6205-NLP/blob/main/Tarea_2_Language_Modeling_y_Nai%CC%88ve_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2obO44rRIDIm"
      },
      "source": [
        "# **Tarea 2 - CC6205 Natural Language Processing 📚**\n",
        "\n",
        "**Integrantes:** Marcelo Rojas y Cristóbal Pérez.\n",
        "\n",
        "**Fecha límite de entrega 📆:** Martes 18 de abril.\n",
        "\n",
        "**Tiempo estimado de dedicación:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpupcv6QW2fd"
      },
      "source": [
        "Bienvenid@s a la segunda tarea del curso de Natural Language Processing (NLP). En esta tarea estaremos modelando probabilísticamente el lenguaje mediante **Languaje Modeling** y clasificando textos mediante el método **Naïve Bayes**. Específicamente, la tarea consta de una parte teórica que busca evaluar conceptos vistos en clases sobre los **Language Models** y una parte práctica donde **programarán a mano** el método **Naïve Bayes**. \n",
        "\n",
        "**Instrucciones:**\n",
        "- La tarea se realiza en grupos de **máximo** 2 personas. Puede ser invidivual pero no es recomendable.\n",
        "- La entrega es a través de u-cursos a más tardar el día estipulado arriba. No se aceptan atrasos.\n",
        "- El formato de entrega es este mismo Jupyter Notebook o el archivo .ipynb si lo ejecuto de forma local.\n",
        "- Al momento de la revisión tu código será ejecutado. Por favor verifica que tu entrega no tenga errores de compilación. \n",
        "- Está **PROHIBIDO** usar cualquier librería que implemente los algoritmos pedidos (Spacy, scikit, etc). Sólo se podrán utilizar las librerías importadas al inicio de la sección de práctica.\n",
        "- En el horario de auxiliar pueden realizar consultas acerca de la tarea a través del canal de Discord del curso.\n",
        "\n",
        "Si aún no han visto las clases, se recomienda visitar los links de las referencias.\n",
        "\n",
        "**Referencias:**\n",
        "\n",
        "Slides:\n",
        "    \n",
        "- [Language Models](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/lmslides.pdf) (slides by Michael Collins)\n",
        "- [Text Classification and Naive Bayes](https://web.stanford.edu/~jurafsky/slp3/slides/7_NB.pdf) (slides by Dan Jurafsky)\n",
        "\n",
        "Videos: \n",
        "\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: Language Models parte 1](https://www.youtube.com/watch?v=9E2jJ6kcb4Y&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=4)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: Language Models parte 2](https://www.youtube.com/watch?v=ZWqbEQXLra0&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=5)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: Language Models parte 3](https://www.youtube.com/watch?v=tsumFqwFlaA&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=6)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: Language Models parte 4](https://www.youtube.com/watch?v=s3TWdv4sqkg&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=7)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: Naive Bayes Parte 1](https://www.youtube.com/watch?v=kG9BK9Oy1hU)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: Naive Bayes Parte 2](https://www.youtube.com/watch?v=Iqte5kKHvzE)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: Naive Bayes Parte 3](https://www.youtube.com/watch?v=TSJg0_X3Abk)\n",
        "\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vY3fYRGVsB_v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JstKx3TiKcIp"
      },
      "source": [
        "---------------------------\n",
        "## Parte 1. Preguntas teóricas (3 pts)\n",
        "\n",
        "En esta parte responderán preguntas **teóricas** sobre los Lenguage Models. Para comprender como funcionan muchas de las técnicas que veremos posteriormente durante el curso será muy útil que dominen estos modelos y sus fundamentos.\n",
        "\n",
        "Contestar cada pregunta en su celda correspondiente y **no extenderse más de 100 palabras** . 🙏\n",
        "\n",
        "**Nota:** Las preguntas deben ser resueltas con desarrollo, pero sin código. Por favor usen $\\LaTeX$ para las fórmulas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHqcRJ7Vr_8x"
      },
      "source": [
        "### 1. Definición de modelo de lenguaje (1 pt)\n",
        "\n",
        "Un grupo de anarquistas primitivistas quiere destruir todas las empresas tecnológicas y departamentos de ciencias de computación porque \"los modelos de lenguaje tienen emociones y como seres sintientes pueden aburrirse de estar sometidos a los humanos y pudieran llegar a conquistar el mundo\". Explique según lo visto en clase qué es un modelo de lenguaje y por qué los anarquistas primitivistas están equivocados. Mencione de qué clase/slide obtuvo la información para que el grupo insurrecto pueda buscar por sí mismo la referencia y evitar la destrucción de nuestro querido DCC. \n",
        "\n",
        "Puede utilizar ChatGPT (debe indicarlo), pero debe mencionar según lo visto en clase por qué la respuesta entregada por ChatGPT es correcta o no."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F5R3Ji7sHjt"
      },
      "source": [
        "` ` \n",
        "\n",
        "**Respuesta ChatGPT:** \n",
        "\n",
        "Un modelo de lenguaje es un algoritmo de aprendizaje automático que utiliza datos de texto para aprender a predecir la siguiente palabra o secuencia de palabras en una oración. Los modelos de lenguaje son utilizados en una amplia variedad de aplicaciones, incluyendo el reconocimiento de voz, la traducción automática, la generación de texto y la clasificación de texto.\n",
        "\n",
        "Es importante señalar que los modelos de lenguaje no tienen emociones ni son seres sintientes. Son simplemente herramientas de software diseñadas para procesar y analizar datos de texto. Aunque pueden ser programados para realizar tareas específicas, no tienen la capacidad de \"aburrirse\" ni de \"conquistar el mundo\".\n",
        "\n",
        "La preocupación expresada por los anarquistas primitivistas es infundada e irracional. La tecnología y la ciencia de la computación han proporcionado avances significativos en la mejora de la vida humana, desde el acceso a información y recursos, hasta la automatización de tareas y la solución de problemas complejos. La destrucción de empresas tecnológicas y departamentos de ciencias de la computación tendría graves consecuencias negativas para la sociedad, desde la pérdida de empleos y la interrupción de servicios críticos, hasta el retroceso en el avance científico y tecnológico.\n",
        "\n",
        "Es importante considerar cuidadosamente las consecuencias de nuestras acciones y decisiones. En lugar de destruir la tecnología y la ciencia de la computación, debemos trabajar juntos para garantizar que estas herramientas se utilicen de manera responsable y ética para el beneficio de la humanidad y el planeta en general.\n",
        "\n",
        "**Respuesta:** \n",
        "\n",
        "La respuesta dada por chatGPT es correcta, es decir, los anarquistas primitivistas están equivocados, pues como se vió en clases (slides 1 y 2 de language models) un modelo de lenguaje es solo un modelamiento estadístico (o probabilístico) del lenguaje y solo se asocian probabilidades a palabras o secuencias de palabras a partir de lo cual se puede predecir o estimar, por lo que carecen de sentimiento.\n",
        "\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hwW-07MrRpt"
      },
      "source": [
        "\n",
        "### 2.1. Probabilidades (1 pt)\n",
        "\n",
        "Asuma que tenemos calculados los parámetros $q(w_i | w_{i-3}, w_{i-2}, w_{i-1})$ para todas las posibles secuencias de tamaño 4 que aparecen en un corpus $\\mathcal{C}$. Dado esto, muestre cómo el modelo le asignaría una probabilidad a la frase `una persona corriendo rápido`.\n",
        "\n",
        "No recomendamos utilizar herramientas como ChatGPT, pues suelen equivocarse en este tipo de preguntas, pero aún así si lo hace, debe indicarlo. Cada vez que mencione contenidos del curso, cite la slide y la clase de la información.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzlQDAVqWNdX"
      },
      "source": [
        "` ` \n",
        "\n",
        "**Respuesta:** \n",
        "Siguiendo la idea de language model, lo que se quiere es calcular la probabilidad de la oraación, esto es, $p(una,persona,corriendo,rápido)$. Como se tienen las probabilidades de n-gramas con $n=4$, la idea es usar markov de orden 3 (Los procesos de Markov se explican a partir de la slide 11).\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "p(una,persona,corriendo,rápido) = p(una) * p(persona|una) * p(corriendo|una,persona) * p(rápido|una,persona,corriendo)\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "Usando padding y Markov de orden 3 (Padding y stop word se explican en las slide 19 y 20):\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "p(una,persona,corriendo,rápido) = p(una,*,*,*) * p(persona|*,*,una) * p(corriendo|*,una,persona) * p(rápido|una,persona,corriendo)\n",
        "\\end{equation}\n",
        "\n",
        "` `"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAej_jqtVwm1"
      },
      "source": [
        "### 2.2 Estimando las probabilidades (1 pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXSFlCIex8kq"
      },
      "source": [
        "#### 2.2.1. Modelo simple (0.5 puntos)\n",
        "\n",
        "Si hubieses tenido que estimar las probabilidades condicionales (parámetros del modelo) $q(w_i | w_{i-3}, w_{i-2}, w_{i-1})$ a partir de $\\mathcal{C}$, ¿cómo la definirías siguiendo el principio de máxima verosimilitud?\n",
        "\n",
        "No recomendamos utilizar herramientas como ChatGPT, pues suelen equivocarse en este tipo de preguntas, pero aún así si lo hace, debe indicarlo. Cada vez que mencione contenidos del curso, cite la slide y la clase de la información.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjNisxPzWsMG"
      },
      "source": [
        "` ` \n",
        "\n",
        "**Respuesta:** \n",
        "\n",
        "Siguiendo el principio de máxima verosimilitud, se tiene que la estimación para $q(w_i | w_{i-3}, w_{i-2}, w_{i-1})$ se puede obtener contando los casos favorables y dividirlos por los casos totales, esto es:\n",
        "\n",
        "\\begin{equation}\n",
        "q(w_i | w_{i-3}, w_{i-2}, w_{i-1}) = \\frac{count(w_{i-3}, w_{i-2}, w_{i-1}, w_i)}{ count(w_{i-3}, w_{i-2}, w_{i-1})}\n",
        "\\end{equation}\n",
        "\n",
        "(Slide 25 de language models)\n",
        "\n",
        "` `"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwNkPIXure0C"
      },
      "source": [
        "#### 2.2.2. Modelo interpolado (0.5 puntos)\n",
        "Muestre cómo se calcularía $q(w_{i} | w_{i-3}, w_{i-2}, w_{i-1})$ usando un modelo que interpola modelos de lenguajes basados en 4-grams, trigramas, bigramas y unigramas. ¿Te fue necesario definir nuevos parámetros? En caso afirmativo, ¿qué los diferencia de los parámetros del modelo simple y qué propiedades deben cumplir?\n",
        "\n",
        "No recomendamos utilizar herramientas como ChatGPT, pues suelen equivocarse en este tipo de preguntas, pero aún así si lo hace, debe indicarlo. Cada vez que mencione contenidos del curso, cite la slide y la clase de la información.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeLZAd0Tr9ne"
      },
      "source": [
        "` ` \n",
        "\n",
        "**Respuesta:** \n",
        "\n",
        "Supongamos que se tienen modelos de lenguajes basados en 4-grams, trigramas, bigramas y unigramas. Se conocen entonces sus parámetros $q_{ml}(w_{i} | w_{i-3}, w_{i-2}, w_{i-1})$, $q_{ml}(w_{i} | w_{i-2}, w_{i-1})$, $q_{ml}(w_{i} | w_{i-1})$ y $q_{ml}(w_{i})$ respectivamente. Luego, usando interpolación lineal:\n",
        "\n",
        "\\begin{equation}\n",
        "q(w_i | w_{i-3}, w_{i-2}, w_{i-1}) = λ_1 q_{ml}(w_{i} | w_{i-3}, w_{i-2}, w_{i-1})+ λ_2 q_{ml}(w_{i} |w_{i-2}, w_{i-1}) + λ_3 q_{ml}(w_{i} | w_{i-1}) + λ_4 q_{ml}(w_{i})\n",
        "\\end{equation}\n",
        "\n",
        "donde $λ_1 + λ_2 + λ_3 + λ_4 = 1$.\n",
        "\n",
        "Los parámetros de los lenguague model se obtienen siguiendo el principio de máxima verosimilitud (como en la parte 2.2.1) y los parámetros $λ_n$ corresponden a híperparámetros del modelo, es decir, no se pueden ajustar a partir de los datos del modelo. Los $λ_n$ se buscan probando múltiples conjuntos de $λ_n$ y se eligen los que minimizan la perplexity.\n",
        "\n",
        "\n",
        "(Slides 40 a la 50 de language models)\n",
        "\n",
        "` `\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdmB-07ZKfaa"
      },
      "source": [
        "-----------------------\n",
        "## Parte 2. Naïve Bayes (3 pts)\n",
        "En esta parte programaremos nuestro primer clasificador de documentos. Para esto implementaremos el método **Naïve Bayes Multinomial** usando **Laplace Smothing**.\n",
        "\n",
        "Por favor, documenten su código. Escriban que hacen las funciones, que reciben, que entregan, etc. Si en algún lugar de su código hacen algo que creen que debe ser explicado, lox comentarios son bienvenidos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpjjKnJUvRiA"
      },
      "source": [
        "### 2.1. Clase para clasificador (0.5 pt)\n",
        "\n",
        "Programa una clase `MyMultinomialNB` que en su inicializador reciba el parametro de generalización `alpha`.\n",
        "\n",
        "```python\n",
        "class MyMultinomialNB(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, ...):\n",
        "    ...\n",
        "```\n",
        "\n",
        "Para más informacion sobre la construcción de esta clase puedes revisar [aquí](https://sklearn-template.readthedocs.io/en/latest/user_guide.html#classifier) \n",
        "\n",
        "Una llamada de ejemplo para crear un objeto de tu clase sería:\n",
        "```python\n",
        "my_clf = MyMultinomialNB(alpha=1)\n",
        "``` \n",
        "lo que debiera crear un clasificador con parámetro `alpha` igual a 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROG50eH0xfxO"
      },
      "source": [
        "### 2.2. Entrenamiento del clasificador (1 pt)\n",
        "\n",
        "Programa el entrenamiento de tu clasificador en el método `fit` de la clase `MyMultinomialNB`. La función debiera recibir el parámetro X que es un `DataFrame` de `pandas` con las columnas `words` y `class_`, donde `words` es una tupla con las palabras asociadas al cada documento y `class_` es el identificador de la clase a la que pertenece cada documento.\n",
        "\n",
        "Para computar el entrenamiento de nuestro clasificador debemos: \n",
        "- extraer el vocabulario,\n",
        "- determinar las probabilidades $p(c_j)$ para cada una de las clases posibles, \n",
        "- determinar las probabilidades $p(w_i|c_j)$ para cada una de las palabras y cada una de las clases usando **Laplace Smothing**.\n",
        "\n",
        "El resultado del metodo `fit` será la misma instancia de nuestro clasificador `self`.\n",
        "\n",
        "```python\n",
        "class MyMultinomialNB(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, ...):\n",
        "    ...\n",
        "\n",
        "  def fit(self, X):\n",
        "    ...\n",
        "    return self\n",
        "```\n",
        "\n",
        "**Underflow prevention:** En vez de hacer muchas multiplicacions de `float`s, reemplácenlas por sumas de logaritmos para prevenir errores de precisión. Revisen la diapo 69 de las slides. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNouTCmR2FgY"
      },
      "source": [
        "### 2.3. Predicción (1 pt)\n",
        "\n",
        "Programa la predicción de tu clasificador en el método `predict` de la clase `MyMultinomialNB`. Al igual que la función `fit`, `predict` debe recibir un `DataFrame` X con valores `None` en la columna `class_` y devolver una lista con las clases que maximizan la probabilidad de Bayes para cada uno de los elmentos de X (filas)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wyhFWeLgYDI"
      },
      "source": [
        "### Implementación 2.1, 2.2 y 2.3 (2.5 pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYFEgTyw2ELL"
      },
      "source": [
        "# Acá implementarán las preguntas 2.1, 2.2 y 2.3,\n",
        "# tu código debiera comenzar así\n",
        "\n",
        "# importamos algunos paquetes necesarios, puede que necesites otros\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "\n",
        "class MyMultinomialNB(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, alpha=1.0):\n",
        "    \"\"\"\n",
        "        Constructor de la clase MyMultinomialNB.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        alpha : float, optional\n",
        "            Coeficiente de Laplace Smoothing. Por defecto es 1.0.\n",
        "    \"\"\"\n",
        "    # acá tu código para inicializar el clasificador\n",
        "    self.alpha = alpha\n",
        "    self.vocab = None\n",
        "    self.classes = None\n",
        "    self.class_probs = None\n",
        "    self.word_probs = None\n",
        "\n",
        "  def fit(self, X):\n",
        "    \"\"\"\n",
        "        Ajusta el modelo a los datos.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pd.DataFrame\n",
        "          Matriz con los textos y clases.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "          Retorna la instancia.\n",
        "    \"\"\"\n",
        "    # acá tu código para el entrenamiento del modelo\n",
        "\n",
        "    # Se extrae el voabulario\n",
        "    self.vocab = set()\n",
        "    for words in X['words']:\n",
        "      self.vocab.update(words)\n",
        "\n",
        "    # Se determina el número de clases\n",
        "    self.classes = X['class_'].unique()\n",
        "    # Se determina el número de documentos\n",
        "    total_docs = len(X)   \n",
        "\n",
        "    # Se determinan las probabilidades p(cj) para cada clase\n",
        "    self.class_probs = {}\n",
        "    for c_j in self.classes:\n",
        "      docs_j = X[ X['class_'] == c_j ]\n",
        "      prob_c_j = np.log( len(docs_j) / total_docs )\n",
        "      self.class_probs[c_j] = prob_c_j\n",
        "\n",
        "    # Se determinan las probabilidades p(wi|cj) para cada palabra y cada clase usando Laplace Smoothing\n",
        "    self.word_probs = {}\n",
        "    for c_j in self.classes:\n",
        "      docs_j = X[ X['class_'] == c_j ]\n",
        "      text_j = [word for words in docs_j['words'] for word in words]\n",
        "      n = len(text_j)\n",
        "\n",
        "      word_probs = {}\n",
        "      for word in self.vocab:\n",
        "        n_k = text_j.count(word)\n",
        "        word_prob = np.log( ( n_k + self.alpha ) / ( n + self.alpha * len(self.vocab )) )\n",
        "        word_probs[word] = word_prob\n",
        "      \n",
        "      self.word_probs[c_j] = word_probs\n",
        "    \n",
        "    return self\n",
        "\n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "        Realiza la clasificación en una matriz X.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pd.DataFrame\n",
        "          Matriz con los textos y clases.\n",
        "        Returns\n",
        "        -------\n",
        "        C : ndarray de forma (n_samples,)\n",
        "          Valores predichos para X.\n",
        "    \"\"\"\n",
        "    # Chequea que fit ha sido ejecutado anteriormente\n",
        "    check_is_fitted(self,['vocab', 'classes', 'class_probs', 'word_probs'])\n",
        "    \n",
        "    # acá tu código para computar la predicción\n",
        "    predictions = []\n",
        "    for doc in X['words']:\n",
        "      max_prob = -np.inf\n",
        "      for c_j in self.classes:\n",
        "        word_prob = self.word_probs[c_j]\n",
        "        prob_c = self.class_probs[c_j]\n",
        "        for word in doc:\n",
        "          if word in word_prob:\n",
        "            prob_c = prob_c + word_prob[word]\n",
        "        if prob_c > max_prob:\n",
        "          max_prob = prob_c\n",
        "          predicted_c = c_j\n",
        "      predictions.append(predicted_c)\n",
        "    return predictions\n",
        "\n",
        "  def predict_proba(self,X):\n",
        "    \"\"\"\n",
        "        Devuelve estimaciones de probabilidad para el vector X.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pd.DataFrame\n",
        "          Matriz con los textos y clases.\n",
        "        Returns\n",
        "        -------\n",
        "        C : array-like of shape (n_samples, n_classes)\n",
        "          Devuelve la probabilidad de las muestras para cada clase en el modelo.\n",
        "    \"\"\"\n",
        "    # Chequea que fit ha sido ejecutado anteriormente\n",
        "    check_is_fitted(self,['vocab', 'classes', 'class_probs', 'word_probs'])\n",
        "\n",
        "    probs = []\n",
        "    # Mismo procedimiento que con predict\n",
        "    for doc in X['words']:\n",
        "      doc_probs = {}\n",
        "      for c_j in self.classes:\n",
        "        prob_c_j = self.class_probs[c_j]\n",
        "        word_probs = self.word_probs[c_j]\n",
        "        doc_prob = prob_c_j\n",
        "        for w_k in doc:\n",
        "          if w_k in word_probs:\n",
        "            doc_prob += word_probs[w_k]\n",
        "        doc_probs[c_j] = doc_prob\n",
        "      # Aquí la diferencia, por Underflow prevention, volvemos al expacio de probabilidades aplicando la exponencial y normalizamos para que la suma de 1\n",
        "      probs.append(\n",
        "          np.exp( list( doc_probs.values() ) ) / np.sum( np.exp( list( doc_probs.values() ) ) )\n",
        "      )\n",
        "    return probs    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(MyMultinomialNB())"
      ],
      "metadata": {
        "id": "-64G_Avow7f1",
        "outputId": "dbeacdda-a6b8-49e7-a316-e2fb4076ef57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on MyMultinomialNB in module __main__ object:\n",
            "\n",
            "class MyMultinomialNB(sklearn.base.BaseEstimator, sklearn.base.ClassifierMixin)\n",
            " |  MyMultinomialNB(alpha=1.0)\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      MyMultinomialNB\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, alpha=1.0)\n",
            " |      Constructor de la clase MyMultinomialNB.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      alpha : float, optional\n",
            " |          Coeficiente de Laplace Smoothing. Por defecto es 1.0.\n",
            " |  \n",
            " |  fit(self, X)\n",
            " |      Ajusta el modelo a los datos.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : pd.DataFrame\n",
            " |        Matriz con los textos y clases.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |        Retorna la instancia.\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Realiza la clasificación en una matriz X.\n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : pd.DataFrame\n",
            " |        Matriz con los textos y clases.\n",
            " |      Returns\n",
            " |      -------\n",
            " |      C : ndarray de forma (n_samples,)\n",
            " |        Valores predichos para X.\n",
            " |  \n",
            " |  predict_proba(self, X)\n",
            " |      Devuelve estimaciones de probabilidad para el vector X.\n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : pd.DataFrame\n",
            " |        Matriz con los textos y clases.\n",
            " |      Returns\n",
            " |      -------\n",
            " |      C : array-like of shape (n_samples, n_classes)\n",
            " |        Devuelve la probabilidad de las muestras para cada clase en el modelo.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |      \n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for `X`.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KOMJ-CS8PRP"
      },
      "source": [
        "### 2.4. Probando el clasificador (0.5 pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hucdz-R7xerG"
      },
      "source": [
        "A continuación probarán el funcionamiento de su clasificador. Para esto, les presentamos un conjunto de documentos de entrenamiento `train_set` divididos en 2 categorias distintas. Ustedes deberán primero entrenar su clasificador usando el método `fit` de su clase y luego, clasificar los documentos del conjunto de prueva `test_set` usando el método `predict`.\n",
        "\n",
        "**NOTA:** Como pueden ver, los objetos `namedtuple`s tienen dos atributos: `words` donde están las palabras del documento y `class_` donde se guarda la clase de ese documento. Estos objetos son inmutables, lo que quiere decir que si quieren modificar un documento y cambiarle la clase, tienen que crear otro documento. Otra cosa es que son tuplas como cualquier otra, es decir se pueden acceder usando indices como `doc[0]` o `doc[1]`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from collections import namedtuple"
      ],
      "metadata": {
        "id": "JjTnFLDGyCEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN1SdLycuK4W",
        "outputId": "6525be02-cd81-4143-a373-60c4d53fb8fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4.1 Primer Caso: Clasificación de ejemplo visto en clases (0.20 pt)"
      ],
      "metadata": {
        "id": "JfS5wXfwxx6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = namedtuple(\n",
        "    \"document\", (\"words\", \"class_\")  # avoid python's keyword collision\n",
        ")\n",
        "\n",
        "train_set = [['Chinese Beijing\tChinese', 'c'],\n",
        "             ['Chinese\tChinese\tShanghai','c'],\n",
        "             ['Chinese\tMacao','c'],\n",
        "             ['Tokyo\tJapan\tChinese','j']]\n",
        "\n",
        "train_set = [document(words=tuple(word_tokenize(d[0])), class_=d[1]) for d in train_set]\n",
        "X_train = pd.DataFrame(data=train_set)\n",
        "\n",
        "test_set = [['Chinese\tChinese\tChinese\tTokyo Japan', None]]\n",
        "test_set = [document(words=tuple(word_tokenize(d[0])), class_=d[1]) for d in test_set]\n",
        "X_test = pd.DataFrame(data=test_set)\n",
        "\n",
        "X_train = pd.DataFrame(data=train_set)\n",
        "print(\"Documentos de entrenamiento\")\n",
        "print(X_train)\n",
        "\n",
        "X_test = pd.DataFrame(data=test_set)\n",
        "print(\"\\nDocumentos de prueba:\")\n",
        "print(X_test)"
      ],
      "metadata": {
        "id": "5yXBv2Kqxyyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63567ea9-23a0-4f41-94e3-dc59407b566c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documentos de entrenamiento\n",
            "                          words class_\n",
            "0   (Chinese, Beijing, Chinese)      c\n",
            "1  (Chinese, Chinese, Shanghai)      c\n",
            "2              (Chinese, Macao)      c\n",
            "3       (Tokyo, Japan, Chinese)      j\n",
            "\n",
            "Documentos de prueba:\n",
            "                                       words class_\n",
            "0  (Chinese, Chinese, Chinese, Tokyo, Japan)   None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Acá probarán su clasificador\n",
        "\n",
        "# inicializamos el clasificador\n",
        "my_clf = MyMultinomialNB(alpha=1)\n",
        "\n",
        "# entrenamos el clasificador para los datos de entrenamiento X_train\n",
        "my_clf.fit(X_train)\n",
        "\n",
        "# acá puedes ver el vocabulario extraído por tu clasificador, \n",
        "# intenta tenerlo guardado en my_clf.vocab\n",
        "print('vocab: ', my_clf.vocab)\n",
        "\n",
        "# si implementaron el método predict_proba en el clasificador (no era obligatorio), \n",
        "# acá lo pueden probar\n",
        "print('\\nTest probs:')\n",
        "print('\\n'.join([str(l) for l in my_clf.predict_proba(X_test)]))\n",
        "\n",
        "# obtengamos las predicciones \n",
        "print('\\nTest predictions:')\n",
        "print('\\n'.join(['{} <- {}'.format(c, ' '.join(s)) for c, s in zip(my_clf.predict(X_test), X_test['words'])]))"
      ],
      "metadata": {
        "id": "UAx0t3zQx2PJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e12e76-198a-4bdb-d3aa-0bd5a8a4925d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab:  {'Macao', 'Shanghai', 'Tokyo', 'Beijing', 'Japan', 'Chinese'}\n",
            "\n",
            "Test probs:\n",
            "[0.68975861 0.31024139]\n",
            "\n",
            "Test predictions:\n",
            "c <- Chinese Chinese Chinese Tokyo Japan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta esperada:**\n",
        "\n",
        "**Nota:** No es necesario que obtenga exactamente la misma probabilidad, lo importante es que su clasificador genere la predicción expuesta.\n",
        "\n",
        "```python\n",
        "vocab:  ['Beijing', 'Chinese', 'Macao', 'Tokyo', 'Japan', 'Shanghai']\n",
        "\n",
        "Test probs:\n",
        "[0.68975861 0.31024139]\n",
        "\n",
        "Test predictions:\n",
        "c <- Chinese Chinese Chinese Tokyo Japan\n",
        "```"
      ],
      "metadata": {
        "id": "dMyCgXxvx29L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4.2 Segundo Caso (0.30 pt)"
      ],
      "metadata": {
        "id": "mpG_t1wTx99m"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLi8PxdV2VQX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef4d6c41-4cd3-4bb8-8862-3b105db22768"
      },
      "source": [
        "document = namedtuple(\n",
        "    \"document\", (\"words\", \"class_\")  # avoid python's keyword collision\n",
        ")\n",
        "\n",
        "train_set = (\n",
        "    document(words=('w03', 'w01', 'w02', 'w06', 'w02', 'w08', 'w07'), class_=0),\n",
        "    document(words=('w05', 'w04', 'w00', 'w06', 'w09', 'w07', 'w06', 'w09', 'w05'), class_=1),\n",
        "    document(words=('w07', 'w06', 'w00', 'w08', 'w01', 'w08', 'w08', 'w09', 'w02'), class_=0),\n",
        "    document(words=('w08', 'w09', 'w02', 'w06', 'w05', 'w08', 'w07'), class_=1),\n",
        "    document(words=('w09', 'w08', 'w05', 'w08', 'w05', 'w00', 'w08'), class_=1),\n",
        "    document(words=('w05', 'w05', 'w06', 'w01', 'w06', 'w08', 'w02'), class_=1),\n",
        "    document(words=('w04', 'w03', 'w07', 'w05', 'w04', 'w00', 'w02'), class_=0),\n",
        "    document(words=('w01', 'w00', 'w01', 'w04', 'w09', 'w02', 'w04', 'w07'), class_=1)\n",
        ")\n",
        "X_train = pd.DataFrame(data=train_set)\n",
        "print(\"Documentos de entrenamiento\")\n",
        "print(X_train)\n",
        "\n",
        "test_set = (document(words=('w02', 'w09', 'w06', 'w01', 'w05', 'w04', 'w03', 'w03'), class_=None),\n",
        "            document(words=('w03', 'w03', 'w04', 'w05', 'w01', 'w06', 'w09', 'w02'), class_=None))\n",
        "X_test = pd.DataFrame(data=test_set)\n",
        "print(\"\\nDocumentos de prueba:\")\n",
        "print(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documentos de entrenamiento\n",
            "                                           words  class_\n",
            "0            (w03, w01, w02, w06, w02, w08, w07)       0\n",
            "1  (w05, w04, w00, w06, w09, w07, w06, w09, w05)       1\n",
            "2  (w07, w06, w00, w08, w01, w08, w08, w09, w02)       0\n",
            "3            (w08, w09, w02, w06, w05, w08, w07)       1\n",
            "4            (w09, w08, w05, w08, w05, w00, w08)       1\n",
            "5            (w05, w05, w06, w01, w06, w08, w02)       1\n",
            "6            (w04, w03, w07, w05, w04, w00, w02)       0\n",
            "7       (w01, w00, w01, w04, w09, w02, w04, w07)       1\n",
            "\n",
            "Documentos de prueba:\n",
            "                                      words class_\n",
            "0  (w02, w09, w06, w01, w05, w04, w03, w03)   None\n",
            "1  (w03, w03, w04, w05, w01, w06, w09, w02)   None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXHwmOWB-4Aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181f67f5-3074-4ada-8e8f-db2afde87655"
      },
      "source": [
        "# Acá probarán su clasificador\n",
        "\n",
        "# inicializamos el clasificador\n",
        "my_clf = MyMultinomialNB(alpha=1)\n",
        "\n",
        "# entrenamos el clasificador para los datos de entrenamiento X_train\n",
        "my_clf.fit(X_train)\n",
        "\n",
        "# acá puedes ver el vocabulario extraído por tu clasificador, \n",
        "# intenta tenerlo guardado en my_clf.vocab\n",
        "print('vocab: ', my_clf.vocab)\n",
        "\n",
        "# si implementaron el método predict_proba en el clasificador (no era obligatorio), \n",
        "# acá lo pueden probar\n",
        "print('\\nTest probs:')\n",
        "print('\\n'.join([str(l) for l in my_clf.predict_proba(X_test)]))\n",
        "\n",
        "# obtengamos las predicciones \n",
        "print('\\nTest predictions:')\n",
        "print('\\n'.join(['{} <- {}'.format(c, ' '.join(s)) for c, s in zip(my_clf.predict(X_test), X_test['words'])]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab:  {'w04', 'w07', 'w09', 'w05', 'w02', 'w06', 'w08', 'w00', 'w03', 'w01'}\n",
            "\n",
            "Test probs:\n",
            "[0.76018101 0.23981899]\n",
            "[0.76018101 0.23981899]\n",
            "\n",
            "Test predictions:\n",
            "0 <- w02 w09 w06 w01 w05 w04 w03 w03\n",
            "0 <- w03 w03 w04 w05 w01 w06 w09 w02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tDZnmns_1dW"
      },
      "source": [
        "#### 2.4.3 (OPCIONAL) Oraciones reales\n",
        "\n",
        "Aquí intentaremos entrenar un clasificador para determinar cuando una oracion en inglés es interrogativa, afirmativa o negativa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCWi3oytd2nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "831c7b3c-5f27-4925-e6b9-68f794c5e3b1"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "document = namedtuple(\n",
        "    \"document\", (\"words\", \"class_\")  # avoid python's keyword collision\n",
        ")\n",
        "\n",
        "train_set2 = [\n",
        "              ['Do you have plenty of time?', '?'],\n",
        "              ['Does she have enough money?','?'],\n",
        "              ['Did they have any useful advice?','?'],\n",
        "              ['What day is today?','?'],\n",
        "              [\"I don't have much time\",'-'],\n",
        "              [\"She doesn't have any money\",'-'],\n",
        "              [\"They didn't have any advice to offer\",'-'],\n",
        "              ['Have you plenty of time?','?'],\n",
        "              ['Has she enough money?','?'],\n",
        "              ['Had they any useful advice?','?'],\n",
        "              [\"I haven't much time\",'-'],\n",
        "              [\"She hasn't any money\",'-'],\n",
        "              [\"He hadn't any advice to offer\",'-'],\n",
        "              ['How are you?','?'],\n",
        "              ['How do you make questions in English?','?'],\n",
        "              ['How long have you lived here?','?'],\n",
        "              ['How often do you go to the cinema?','?'],\n",
        "              ['How much is this dress?','?'],\n",
        "              ['How old are you?','?'],\n",
        "              ['How many people came to the meeting?','?'],\n",
        "              ['I’m from France','+'],\n",
        "              ['I come from the UK','+'],\n",
        "              ['My phone number is 61709832145','+'],\n",
        "              ['I work as a tour guide for a local tour company','+'],\n",
        "              ['I’m not dating anyone','-'],\n",
        "              ['I live with my wife and children','+'],\n",
        "              ['I often do morning exercises at 6am','+'],\n",
        "              ['I run everyday','+'],\n",
        "              ['She walks very slowly','+'],\n",
        "              ['They eat a lot of meat daily','+'],\n",
        "              ['We were in France that day', '+'],\n",
        "              ['He speaks very fast', '+'],\n",
        "              ['They told us they came back early', '+'],\n",
        "              [\"I told her I'll be there\", '+']\n",
        "]\n",
        "train_set2 = [document(words=tuple(word_tokenize(d[0])), class_=d[1]) for d in train_set2]\n",
        "X_train2 = pd.DataFrame(data=train_set2)\n",
        "print(\"Documentos de entrenamiento:\")\n",
        "print(X_train2)\n",
        "\n",
        "test_set2 = [\n",
        "             ['Do you know who lives here?','?'],\n",
        "             ['What time is it?','?'],\n",
        "             ['Can you tell me where she comes from?','?'],\n",
        "             ['How are you?','?'],\n",
        "             ['I fill good today', '+'],\n",
        "             ['There is a lot of history here','+'],\n",
        "             ['I love programming','+'],\n",
        "             ['He told us not to make so much noise','+'],  # interesing case\n",
        "             ['We were asked not to park in front of the house','+'],  # interesing case\n",
        "             [\"I don't have much time\",'-'],\n",
        "             [\"She doesn't have any money\",'-'],\n",
        "             [\"They didn't have any advice to offer\",'-'],\n",
        "             ['I am not really sure','+']\n",
        "]\n",
        "test_set2 = [document(words=tuple(word_tokenize(d[0])), class_=d[1]) for d in test_set2]\n",
        "X_test2 = pd.DataFrame(data=test_set2)\n",
        "print(\"\\nDocumentos de prueba:\")\n",
        "print(X_test2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documentos de entrenamiento:\n",
            "                                                words class_\n",
            "0                (Do, you, have, plenty, of, time, ?)      ?\n",
            "1                 (Does, she, have, enough, money, ?)      ?\n",
            "2           (Did, they, have, any, useful, advice, ?)      ?\n",
            "3                           (What, day, is, today, ?)      ?\n",
            "4                      (I, do, n't, have, much, time)      -\n",
            "5                  (She, does, n't, have, any, money)      -\n",
            "6      (They, did, n't, have, any, advice, to, offer)      -\n",
            "7                    (Have, you, plenty, of, time, ?)      ?\n",
            "8                        (Has, she, enough, money, ?)      ?\n",
            "9                 (Had, they, any, useful, advice, ?)      ?\n",
            "10                         (I, have, n't, much, time)      -\n",
            "11                        (She, has, n't, any, money)      -\n",
            "12             (He, had, n't, any, advice, to, offer)      -\n",
            "13                                 (How, are, you, ?)      ?\n",
            "14    (How, do, you, make, questions, in, English, ?)      ?\n",
            "15             (How, long, have, you, lived, here, ?)      ?\n",
            "16      (How, often, do, you, go, to, the, cinema, ?)      ?\n",
            "17                    (How, much, is, this, dress, ?)      ?\n",
            "18                            (How, old, are, you, ?)      ?\n",
            "19     (How, many, people, came, to, the, meeting, ?)      ?\n",
            "20                            (I, ’, m, from, France)      +\n",
            "21                           (I, come, from, the, UK)      +\n",
            "22               (My, phone, number, is, 61709832145)      +\n",
            "23  (I, work, as, a, tour, guide, for, a, local, t...      +\n",
            "24                     (I, ’, m, not, dating, anyone)      -\n",
            "25           (I, live, with, my, wife, and, children)      +\n",
            "26        (I, often, do, morning, exercises, at, 6am)      +\n",
            "27                                 (I, run, everyday)      +\n",
            "28                         (She, walks, very, slowly)      +\n",
            "29               (They, eat, a, lot, of, meat, daily)      +\n",
            "30                  (We, were, in, France, that, day)      +\n",
            "31                           (He, speaks, very, fast)      +\n",
            "32          (They, told, us, they, came, back, early)      +\n",
            "33                  (I, told, her, I, 'll, be, there)      +\n",
            "\n",
            "Documentos de prueba:\n",
            "                                                words class_\n",
            "0                (Do, you, know, who, lives, here, ?)      ?\n",
            "1                             (What, time, is, it, ?)      ?\n",
            "2    (Can, you, tell, me, where, she, comes, from, ?)      ?\n",
            "3                                  (How, are, you, ?)      ?\n",
            "4                              (I, fill, good, today)      +\n",
            "5              (There, is, a, lot, of, history, here)      +\n",
            "6                              (I, love, programming)      +\n",
            "7      (He, told, us, not, to, make, so, much, noise)      +\n",
            "8   (We, were, asked, not, to, park, in, front, of...      +\n",
            "9                      (I, do, n't, have, much, time)      -\n",
            "10                 (She, does, n't, have, any, money)      -\n",
            "11     (They, did, n't, have, any, advice, to, offer)      -\n",
            "12                         (I, am, not, really, sure)      +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wdp22w2ArUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7e24f3-f0f2-40e6-b478-62b2ad3d09ad"
      },
      "source": [
        "# Acá probarán su clasificador y computaremos algunas métricas de evaluacion\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# inicializamos el clasificador\n",
        "my_clf2 = MyMultinomialNB(alpha=1)\n",
        "\n",
        "# entrenamos el clasificador para los datos de entrenamiento X_train2\n",
        "my_clf2.fit(X_train2)\n",
        "\n",
        "# acá puedes ver el vocabulario extraído por tu clasificador, \n",
        "# intenta tenerlo guardado en my_clf.vocab\n",
        "print('vocab: ', len(my_clf2.vocab), my_clf2.vocab)\n",
        "\n",
        "# si implementaron el método predict_proba en el clasificador (no era obligatorio), \n",
        "# acá lo pueden probar\n",
        "# print('\\nTest probs:')\n",
        "# print('\\n'.join([str(l) for l in my_clf.predict_proba(X_test2)]))\n",
        "\n",
        "# obtengamos las predicciones para X_test2\n",
        "print('\\nTest predictions:')\n",
        "my_y_preds = my_clf2.predict(X_test2) # know no está en el dataframe o dict\n",
        "print('\\n'.join(['{} <- {}'.format(c, ' '.join(s)) for c, s in zip(my_y_preds, X_test2['words'])]))\n",
        "print(classification_report(y_true=X_test2['class_'], y_pred=my_y_preds, target_names=['?', '+', '-']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab:  109 {'’', 'Did', 'guide', 'What', 'go', 'exercises', 'today', 'us', '61709832145', 'is', 'were', 'I', 'number', 'her', 'dress', 'Has', 'from', 'do', 'day', 'and', 'plenty', 'came', 'come', 'How', 'everyday', 'meeting', 'children', 'long', 'the', 'walks', 'very', 'Does', 'are', 'has', '6am', 'often', 'that', 'cinema', 'be', 'of', 'm', 'any', 'lived', 'at', 'anyone', 'old', 'make', 'eat', 'Have', 'phone', \"'ll\", 'work', 'enough', 'a', 'she', 'not', 'English', 'my', 'live', 'dating', 'speaks', 'fast', 'We', 'as', 'morning', 'UK', 'daily', 'there', 'Had', 'with', 'lot', 'offer', 'in', 'My', 'much', 'many', 'She', 'questions', 'run', 'slowly', 'to', 'people', 'tour', 'meat', 'here', 'local', 'He', 'back', \"n't\", 'for', 'this', 'did', 'have', 'company', 'you', 'wife', 'They', 'time', 'Do', 'they', 'early', 'advice', 'France', 'money', 'does', 'useful', '?', 'had', 'told'}\n",
            "\n",
            "Test predictions:\n",
            "? <- Do you know who lives here ?\n",
            "? <- What time is it ?\n",
            "? <- Can you tell me where she comes from ?\n",
            "? <- How are you ?\n",
            "+ <- I fill good today\n",
            "+ <- There is a lot of history here\n",
            "+ <- I love programming\n",
            "- <- He told us not to make so much noise\n",
            "? <- We were asked not to park in front of the house\n",
            "- <- I do n't have much time\n",
            "- <- She does n't have any money\n",
            "- <- They did n't have any advice to offer\n",
            "+ <- I am not really sure\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           ?       1.00      0.67      0.80         6\n",
            "           +       0.75      1.00      0.86         3\n",
            "           -       0.80      1.00      0.89         4\n",
            "\n",
            "    accuracy                           0.85        13\n",
            "   macro avg       0.85      0.89      0.85        13\n",
            "weighted avg       0.88      0.85      0.84        13\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta aproximada:**\n",
        "\n",
        "**Nota:** No es necesario que obtenga exactamente los mismos resultados.\n",
        "\n",
        "```python\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           ?       1.00      0.67      0.80         6\n",
        "           +       0.75      1.00      0.86         3\n",
        "           -       0.80      1.00      0.89         4\n",
        "\n",
        "    accuracy                           0.85        13\n",
        "   macro avg       0.85      0.89      0.85        13\n",
        "weighted avg       0.88      0.85      0.84        13\n",
        "```"
      ],
      "metadata": {
        "id": "WXbg6sNTdAlO"
      }
    }
  ]
}